{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b73997",
   "metadata": {},
   "source": [
    "# Amany Gaber Okaila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3dd0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs \n",
    "from urllib.request import urlopen \n",
    "import csv\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf94794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a job title (at most tree words ) : data analyst\n"
     ]
    }
   ],
   "source": [
    "page_num = 0\n",
    "job = input('Enter a job title (at most tree words ) : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1649e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles_list = []\n",
    "company_name_list = []\n",
    "location_list = []\n",
    "job_time = []\n",
    "requirmets_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda24452",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True :\n",
    "        if len(job.split()) == 2 :\n",
    "            url = f'https://wuzzuf.net/search/jobs/?a=spbl&q={job.split()[0]}%20{job.split()[1]}&start={page_num}'\n",
    "        elif len(job.split()) == 1 :\n",
    "            url = f'https://wuzzuf.net/search/jobs/?a=spbl&q={job.split()[0]}&start={page_num}'\n",
    "        elif len(job.split()) == 3 :\n",
    "            url = f'https://wuzzuf.net/search/jobs/?a=spbl&q={job.split()[0]}%20{job.split()[1]}%20{job.split()[2]}&start={page_num}'\n",
    "        elif len(job.split()) == 3 :\n",
    "            url = f'https://wuzzuf.net/search/jobs/?a=spbl&q={job.split()[0]}%20{job.split()[1]}%20{job.split()[2]}%20{job.split()[3]}&start={page_num}'\n",
    "       \n",
    "        client = urlopen(url)\n",
    "        html = client.read()\n",
    "        client.close()\n",
    "        \n",
    "        soup = bs(html , 'lxml')\n",
    "        \n",
    "        containers = soup.find_all('div' , {'class' : 'css-1gatmva e1v1l3u10'})\n",
    "        \n",
    "       \n",
    "\n",
    "        for container in containers :\n",
    "\n",
    "            jtitle = container.findAll ('h2' , {'class' : 'css-m604qf'})\n",
    "            job_titles_list.append(jtitle[0].text)\n",
    "\n",
    "            cname = container.findAll(\"a\" , {'class' : 'css-17s97q8'})\n",
    "            company_name_list.append(cname[0].text.strip())\n",
    "\n",
    "            add = container.findAll(\"span\" , {'class' : 'css-5wys0k'})\n",
    "            location_list.append(add[0].text.strip())\n",
    "\n",
    "            jtime = container.findAll(\"div\" , {'class' : 'css-1lh32fc'})\n",
    "            job_time.append(jtime[0].text)\n",
    "\n",
    "            req = containers[0].findAll(\"div\" , {'class' : 'css-y4udm8'})\n",
    "            requirmets_list.append(req[0].text)\n",
    "            \n",
    "        page_num = page_num + 1\n",
    "            \n",
    "        if page_num >= 28:       # 28 as I know num of pages with the example of 'data analyst' can I update it using the next block\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ecb508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"css-8neukt\">Showing 406 - 183 of 183</li>]\n",
      "Enter num of pages (from output of previous block): 28\n"
     ]
    }
   ],
   "source": [
    "# to check num of pages run it then edit it in the previous block\n",
    "page_num = 0\n",
    "container_4_pages = soup.find_all('div' , {'class' : 'css-9i2afk'})\n",
    "num_of_pages = container_4_pages[0].findAll(\"li\" , {'class' : 'css-8neukt'})\n",
    "print(num_of_pages)\n",
    "num_of_pages = int(input('Enter num of pages (from output of previous block): '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8102327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [job_titles_list , company_name_list , location_list , job_time , requirmets_list]\n",
    "exported = zip_longest(*file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d77b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'C:/Users/Blu-Ray/Desktop/{job} jobs.csv' , 'w') as myfile :\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(['job title' , 'company name' , 'location' , 'time' , 'Requirments'])\n",
    "    wr.writerows(exported)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
